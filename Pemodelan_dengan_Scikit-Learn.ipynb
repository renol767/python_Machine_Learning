{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa165ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset_clean: (12316, 18)\n",
      "Before imputation:\n",
      "Administrative             14\n",
      "Administrative_Duration    14\n",
      "Informational              14\n",
      "Informational_Duration     14\n",
      "ProductRelated             14\n",
      "ProductRelated_Duration    14\n",
      "BounceRates                14\n",
      "ExitRates                  14\n",
      "PageValues                  0\n",
      "SpecialDay                  0\n",
      "Month                       0\n",
      "OperatingSystems            0\n",
      "Browser                     0\n",
      "Region                      0\n",
      "TrafficType                 0\n",
      "VisitorType                 0\n",
      "Weekend                     0\n",
      "Revenue                     0\n",
      "dtype: int64\n",
      "112\n",
      "\n",
      "After imputation:\n",
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n",
      "0\n",
      "                         min  max\n",
      "Administrative           0.0  1.0\n",
      "Administrative_Duration  0.0  1.0\n",
      "Informational            0.0  1.0\n",
      "Informational_Duration   0.0  1.0\n",
      "ProductRelated           0.0  1.0\n",
      "ProductRelated_Duration  0.0  1.0\n",
      "BounceRates              0.0  1.0\n",
      "ExitRates                0.0  1.0\n",
      "PageValues               0.0  1.0\n",
      "['Aug' 'Dec' 'Feb' 'Jul' 'June' 'Mar' 'May' 'Nov' 'Oct' 'Sep']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "['New_Visitor' 'Other' 'Returning_Visitor']\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DARI MODUL SEBELUMNYA\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('online_raw.csv')\n",
    "\n",
    "#Drop rows with missing value   \n",
    "dataset_clean = dataset.dropna()\n",
    "print('Ukuran dataset_clean:', dataset_clean.shape)\n",
    "\n",
    "# FILL NA MENGGUNAKAN MEDIAN\n",
    "print(\"Before imputation:\")\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nAfter imputation:\")\n",
    "# Fill missing value with median of feature value  \n",
    "dataset.fillna(dataset.median(), inplace = True)\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())\n",
    "\n",
    "# PREPROCESSING\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "#Define MinMaxScaler as scaler  \n",
    "scaler = MinMaxScaler()  \n",
    "#list all the feature that need to be scaled  \n",
    "scaling_column = [\n",
    "    'Administrative','Administrative_Duration','Informational','Informational_Duration',\n",
    "    'ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\n",
    "#Apply fit_transfrom to scale selected feature  \n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\n",
    "#Cheking min and max value of the scaling_column\n",
    "print(dataset[scaling_column].describe().T[['min','max']])\n",
    "\n",
    "# PREPROCESSING Konversi String ke Numerik karena MinMaxScaler Khusus Numerik\n",
    "# Karena Month Dan Visitor type Bentuknya Object\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert feature/column 'Month'\n",
    "LE = LabelEncoder()\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['Month'].unique()))\n",
    "print('')\n",
    "\n",
    "# Convert feature/column 'VisitorType'\n",
    "LE = LabelEncoder()\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8546f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (12330, 17)\n",
      "Shape of y: (12330,)\n"
     ]
    }
   ],
   "source": [
    "# removing the target column Revenue from dataset and assigning to X\n",
    "X = dataset.drop(['Revenue'], axis = 1)\n",
    "# assigning the target column Revenue to y\n",
    "y = dataset['Revenue']\n",
    "# checking the shapes\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee1a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (9864, 17)\n",
      "Shape of y_train : (9864,)\n",
      "Shape of X_test : (2466, 17)\n",
      "Shape of y_test : (2466,)\n"
     ]
    }
   ],
   "source": [
    "# SPLIT Kedalam Train dan Test dengan perbandingan 80 Train 20 test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# splitting the X, and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# checking the shapes\n",
    "print(\"Shape of X_train :\", X_train.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of X_test :\", X_test.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f301e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Call the classifier\n",
    "model = DecisionTreeClassifier()\n",
    "# Fit the classifier to the training data\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88a8c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466,)\n"
     ]
    }
   ],
   "source": [
    "# Apply the classifier/model to the test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a927a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8588807785888077\n",
      "\n",
      "Confusion matrix:\n",
      "[[1887  157]\n",
      " [ 191  231]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.92      0.92      2044\n",
      "        True       0.60      0.55      0.57       422\n",
      "\n",
      "    accuracy                           0.86      2466\n",
      "   macro avg       0.75      0.74      0.74      2466\n",
      "weighted avg       0.85      0.86      0.86      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# evaluating the model\n",
    "print('Training Accuracy :', model.score(X_train, y_train))\n",
    "print('Testing Accuracy :', model.score(X_test, y_test))\n",
    "\n",
    "# confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# classification report\n",
    "print('\\nClassification report:')\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485afe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
