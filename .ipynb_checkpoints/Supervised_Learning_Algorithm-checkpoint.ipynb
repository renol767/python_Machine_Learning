{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac6f64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset_clean: (12316, 18)\n",
      "Before imputation:\n",
      "Administrative             14\n",
      "Administrative_Duration    14\n",
      "Informational              14\n",
      "Informational_Duration     14\n",
      "ProductRelated             14\n",
      "ProductRelated_Duration    14\n",
      "BounceRates                14\n",
      "ExitRates                  14\n",
      "PageValues                  0\n",
      "SpecialDay                  0\n",
      "Month                       0\n",
      "OperatingSystems            0\n",
      "Browser                     0\n",
      "Region                      0\n",
      "TrafficType                 0\n",
      "VisitorType                 0\n",
      "Weekend                     0\n",
      "Revenue                     0\n",
      "dtype: int64\n",
      "112\n",
      "\n",
      "After imputation:\n",
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n",
      "0\n",
      "                         min  max\n",
      "Administrative           0.0  1.0\n",
      "Administrative_Duration  0.0  1.0\n",
      "Informational            0.0  1.0\n",
      "Informational_Duration   0.0  1.0\n",
      "ProductRelated           0.0  1.0\n",
      "ProductRelated_Duration  0.0  1.0\n",
      "BounceRates              0.0  1.0\n",
      "ExitRates                0.0  1.0\n",
      "PageValues               0.0  1.0\n",
      "['Aug' 'Dec' 'Feb' 'Jul' 'June' 'Mar' 'May' 'Nov' 'Oct' 'Sep']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "['New_Visitor' 'Other' 'Returning_Visitor']\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DARI MODUL SEBELUMNYA\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('online_raw.csv')\n",
    "\n",
    "#Drop rows with missing value   \n",
    "dataset_clean = dataset.dropna()\n",
    "print('Ukuran dataset_clean:', dataset_clean.shape)\n",
    "\n",
    "# FILL NA MENGGUNAKAN MEDIAN\n",
    "print(\"Before imputation:\")\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nAfter imputation:\")\n",
    "# Fill missing value with median of feature value  \n",
    "dataset.fillna(dataset.median(), inplace = True)\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())\n",
    "\n",
    "# PREPROCESSING\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "#Define MinMaxScaler as scaler  \n",
    "scaler = MinMaxScaler()  \n",
    "#list all the feature that need to be scaled  \n",
    "scaling_column = [\n",
    "    'Administrative','Administrative_Duration','Informational','Informational_Duration',\n",
    "    'ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\n",
    "#Apply fit_transfrom to scale selected feature  \n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\n",
    "#Cheking min and max value of the scaling_column\n",
    "print(dataset[scaling_column].describe().T[['min','max']])\n",
    "\n",
    "# PREPROCESSING Konversi String ke Numerik karena MinMaxScaler Khusus Numerik\n",
    "# Karena Month Dan Visitor type Bentuknya Object\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert feature/column 'Month'\n",
    "LE = LabelEncoder()\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['Month'].unique()))\n",
    "print('')\n",
    "\n",
    "# Convert feature/column 'VisitorType'\n",
    "LE = LabelEncoder()\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958a6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (12330, 17)\n",
      "Shape of y: (12330,)\n",
      "Shape of X_train : (9864, 17)\n",
      "Shape of y_train : (9864,)\n",
      "Shape of X_test : (2466, 17)\n",
      "Shape of y_test : (2466,)\n"
     ]
    }
   ],
   "source": [
    "# PREPARE PART 2\n",
    "# removing the target column Revenue from dataset and assigning to X\n",
    "X = dataset.drop(['Revenue'], axis = 1)\n",
    "# assigning the target column Revenue to y\n",
    "y = dataset['Revenue']\n",
    "# checking the shapes\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# SPLIT Kedalam Train dan Test dengan perbandingan 80 Train 20 test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# splitting the X, and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# checking the shapes\n",
    "print(\"Shape of X_train :\", X_train.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of X_test :\", X_test.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Call the classifier\n",
    "model = DecisionTreeClassifier()\n",
    "# Fit the classifier to the training data\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a57393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8600973236009732\n",
      "\n",
      "Confusion matrix\n",
      "[[2008   36]\n",
      " [ 317  105]]\n",
      "\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.98      0.92      2044\n",
      "        True       0.74      0.25      0.37       422\n",
      "\n",
      "    accuracy                           0.86      2466\n",
      "   macro avg       0.80      0.62      0.65      2466\n",
      "weighted avg       0.84      0.86      0.83      2466\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\renol n\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Call the classifier\n",
    "logreg = LogisticRegression()\n",
    "# Fit the classifier to the training data  \n",
    "logreg = logreg.fit(X_train,y_train)\n",
    "#Training Model: Predict \n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "#Evaluate Model Performance\n",
    "print('Training Accuracy :', model.score(X_train, y_train))  \n",
    "print('Testing Accuracy :', model.score(X_test, y_test))  \n",
    "\n",
    "# confusion matrix\n",
    "print('\\nConfusion matrix')  \n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)\n",
    "\n",
    "# classification report  \n",
    "print('\\nClassification report')  \n",
    "cr = classification_report(y_test, y_pred)  \n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db65442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8607731819410651\n"
     ]
    }
   ],
   "source": [
    "# Model Machine Learning Menggunakan Decission Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Call the classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "# Fit the classifier to the training data\n",
    "decision_tree = decision_tree.fit(X_train,y_train)\n",
    "\n",
    "# evaluating the decision_tree performance\n",
    "print('Training Accuracy :', decision_tree.score(X_train, y_train))\n",
    "print('Testing Accuracy :', decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c112d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
